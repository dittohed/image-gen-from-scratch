{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to train a simple diffusion-like model to generate\n",
    "MNIST-like images. It's inspired by https://huggingface.co/learn/diffusion-course/en/unit1/3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 3\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_imgs(x: torch.Tensor, title: str = '', from_gpu: bool = False):\n",
    "    if from_gpu:\n",
    "        x = x.detach().cpu().clip(0, 1)  # Clip just in case predictions are a bit off\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.imshow(torchvision.utils.make_grid(x)[0], cmap='Greys');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(\n",
    "    root='../local',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "x, _ = next(iter(dataloader))\n",
    "x = x[:8]  # Take only a few images for visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tensor_imgs(x, 'MNIST images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt(x: torch.Tensor, amount: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Corrupt images from `x` with random noise from [0, 1] interval.\n",
    "\n",
    "    Each image is corrupted to a different degree, according to `amount`,\n",
    "    which should be a 1D tensor of size 1 or `x.shape[0]`.\n",
    "    \"\"\"\n",
    "\n",
    "    noise = torch.rand_like(x)\n",
    "    amount = amount.view(-1, 1, 1, 1)  # To make sure broadcasting works\n",
    "\n",
    "    return x*(1-amount) + noise*amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how various degrees of corruption look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount = torch.linspace(0, 1, x.shape[0])\n",
    "x_corr = corrupt(x, amount)\n",
    "\n",
    "show_tensor_imgs(x_corr, 'Images with increasing amount of corruption (0-1)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model & other stuff before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet(in_channels=1, out_channels=1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    tqdm_it = tqdm(dataloader, total=len(dataloader), leave=True)\n",
    "    tqdm_it.set_description(f'Epoch: [{epoch+1}/{NUM_EPOCHS}]')\n",
    "\n",
    "    for x, _ in tqdm_it:\n",
    "        x = x.to(device)\n",
    "        amount = torch.rand(x.shape[0]).to(device)\n",
    "        x_corr = corrupt(x, amount)\n",
    "        \n",
    "        x_reconstr = model(x_corr)\n",
    "        loss = loss_fn(x_reconstr, x)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tqdm_it.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = next(iter(dataloader))\n",
    "x = x[:8]\n",
    "\n",
    "show_tensor_imgs(x, 'Original images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(device)\n",
    "amount = torch.linspace(0, 1, x.shape[0])\n",
    "x_corr = corrupt(x, amount)\n",
    "\n",
    "show_tensor_imgs(x_corr, 'Corrupted images', from_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    x_reconstr = model(x_corr)\n",
    "\n",
    "show_tensor_imgs(x_reconstr, 'Reconstructed images', from_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling in multiple steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate images in multiple steps (for each step, next prediction\n",
    "is a weighted sum of the current image and the current prediction, where\n",
    "the prediction's weight increases over time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLING_STEPS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "preds = []\n",
    "\n",
    "x = torch.rand(8, 1, 28, 28).to(device)\n",
    "\n",
    "for i in range(N_SAMPLING_STEPS):\n",
    "    inputs.append(x.cpu())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "    preds.append(pred.cpu())\n",
    "    \n",
    "    mix_factor = 1 / (N_SAMPLING_STEPS - i)\n",
    "    x = mix_factor*pred + (1-mix_factor)*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(N_SAMPLING_STEPS, 2, figsize=(10, N_SAMPLING_STEPS), sharex=True)\n",
    "axs[0, 0].set_title('Input')\n",
    "axs[0, 1].set_title('Prediction')\n",
    "\n",
    "for i in range(N_SAMPLING_STEPS):\n",
    "    axs[i, 0].imshow(\n",
    "        torchvision.utils.make_grid(inputs[i])[0].clip(0, 1), cmap='Greys'\n",
    "    )\n",
    "    axs[i, 1].imshow(\n",
    "        torchvision.utils.make_grid(preds[i])[0].clip(0, 1), cmap='Greys'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

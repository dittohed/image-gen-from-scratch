{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to train a simple MLP VAE to generate MNIST-like images.\n",
    "It's inspired by https://www.youtube.com/watch?v=VELQT1-hILo&t=1707s.\n",
    "\n",
    "For losses, following the video above, I use 'sum' reduction instead of typical 'mean' because it gives better\n",
    "results. That's probably because it sets a better balance between reconstruction \n",
    "and KL divergence losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import VariationalAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 28\n",
    "HIDDEN_DIM = 256\n",
    "LATENT_DIM = 64\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "LR = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing stuff for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.MNIST(\n",
    "    root='../local',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = VariationalAutoencoder(\n",
    "    input_dim=IMG_SIZE*IMG_SIZE,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    latent_dim=LATENT_DIM\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_bce = torch.nn.BCEWithLogitsLoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5]: 100%|██████████| 468/468 [00:29<00:00, 15.77it/s, loss=2.69e+4]\n",
      "Epoch: [2/5]: 100%|██████████| 468/468 [00:17<00:00, 27.22it/s, loss=2.35e+4]\n",
      "Epoch: [3/5]: 100%|██████████| 468/468 [00:13<00:00, 34.99it/s, loss=2.17e+4]\n",
      "Epoch: [4/5]: 100%|██████████| 468/468 [00:13<00:00, 34.16it/s, loss=2.1e+4] \n",
      "Epoch: [5/5]: 100%|██████████| 468/468 [00:28<00:00, 16.30it/s, loss=1.96e+4]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    classes = []\n",
    "    latents = []\n",
    "\n",
    "    tqdm_it = tqdm(dataloader, total=len(dataloader), leave=True)\n",
    "    tqdm_it.set_description(f'Epoch: [{epoch+1}/{NUM_EPOCHS}]')\n",
    "\n",
    "    for x, y in tqdm_it:\n",
    "        x = x.view(BATCH_SIZE, -1).to(device)\n",
    "        x_reconstr, latent_sampled, mu, logvar = model(x)\n",
    "\n",
    "        loss_reconstr = loss_bce(x_reconstr, x)\n",
    "        loss_kl = -1/2 * torch.sum(\n",
    "            1 + logvar - torch.exp(logvar) - mu.pow(2)\n",
    "        )\n",
    "        loss = loss_reconstr + loss_kl \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        classes.append(y.numpy())\n",
    "        latents.append(latent_sampled.detach().cpu().numpy())\n",
    "        tqdm_it.set_postfix(loss=loss.item())\n",
    "\n",
    "    # TODO: some kind of fancy plotting every `n` epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating new samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate an example of a desired digit, we'll first calculate `mu` and `logvar`\n",
    "for a random image of a picked digit, then use them to sample new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIGIT = 0\n",
    "NUM_SAMPLES = 3  # Number of generated samples per digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idx = np.random.choice(\n",
    "    torch.nonzero(dataset.train_labels == DIGIT).flatten()\n",
    ")\n",
    "img = dataset.train_data[rand_idx:rand_idx+1, :, :] / 255\n",
    "save_image(img, f'{DIGIT}_original.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, logvar = model.encode(img.view(1, -1).to(device))\n",
    "\n",
    "for i in range(NUM_SAMPLES):\n",
    "    eps = torch.randn_like(logvar)\n",
    "    latent_sampled = mu + torch.sqrt(torch.exp(logvar))*eps\n",
    "    img_sampled = model.decode(latent_sampled, apply_sigmoid=True)\n",
    "    save_image(img_sampled.view(1, IMG_SIZE, IMG_SIZE), f'{DIGIT}_sampled_v{i+1}.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
